{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_mit_test = 'mitbih_test.csv'\n",
    "file_mit_train = 'mitbih_train.csv'\n",
    "file_ptbdb_ab = 'ptbdb_abnormal.csv'\n",
    "file_ptbdb_no = 'ptbdb_normal.csv'\n",
    "\n",
    "df_mit_test = pd.read_csv(file_mit_test, header=None)\n",
    "df_mit_train = pd.read_csv(file_mit_train, header=None)\n",
    "df_ptbdb_ab = pd.read_csv(file_ptbdb_ab, header=None)\n",
    "df_ptbdb_no = pd.read_csv(file_ptbdb_no, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "X_train = df_mit_train.iloc[:,:-1]\n",
    "Y_train = df_mit_train.iloc[:,-1]\n",
    "X_test = df_mit_test.iloc[:,:-1]\n",
    "Y_test = df_mit_test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-nearest neighbors score: 0.9746939521286314\n"
     ]
    }
   ],
   "source": [
    "# (1) k-nearest neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=2)\n",
    "clf.fit(X_train,Y_train)\n",
    "print('k-nearest neighbors score:', clf.score(X_test, Y_test))\n",
    "# score of the k-nearest neighbors is 0.9747 with two neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-neighbors regression score: 0.9336753678306022\n"
     ]
    }
   ],
   "source": [
    "# (2) K-neighbors regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "Kreg = KNeighborsRegressor(n_neighbors=3)\n",
    "Kreg.fit(X_train,Y_train)\n",
    "print('K-neighbors regression score:', Kreg.score(X_test,Y_test))\n",
    "# score with 3 neighbors is 0.9337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.6056893850937954\n",
      "Test score: 0.5986016492861155\n"
     ]
    }
   ],
   "source": [
    "# (3) Ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "Ridgereg = Ridge().fit(X_train,Y_train)\n",
    "print('Training score:', Ridgereg.score(X_train,Y_train))\n",
    "print('Test score:',Ridgereg.score(X_test,Y_test))\n",
    "# Ridge score is 0.5986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score (alpha =10): 0.6056893850937954\n",
      "Test score(alpha = 10): 0.5986016492861155\n"
     ]
    }
   ],
   "source": [
    "Ridge10 = Ridge(alpha = 10).fit(X_train,Y_train)\n",
    "print('Training score (alpha =10):', Ridgereg.score(X_train,Y_train))\n",
    "print('Test score(alpha = 10):',Ridgereg.score(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge01 = Ridge(alpha = 0.1).fit(X_train,Y_train)\n",
    "print('Training score (alpha =10):', Ridgereg.score(X_train,Y_train))\n",
    "print('Test score(alpha = 10):',Ridgereg.score(X_test,Y_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) Linear model for classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression().fit(X_train, Y_train)\n",
    "print('Training set score:', logreg.score(X_train, Y_train))\n",
    "print('Test score:', logreg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log100reg = LogisticRegression(C=100).fit(X_train, Y_train)\n",
    "print('Training set score:', log100reg.score(X_train, Y_train))\n",
    "print('Test score:', log100reg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log001reg = LogisticRegression(C=0.01).fit(X_train, Y_train)\n",
    "print('Training set score:', log001reg.score(X_train, Y_train))\n",
    "print('Test score:', log001reg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(5) support vector machine (SVM)\n",
    "from sklearn.svm import LinearSVC\n",
    "linear_svm = LinearSVC().fit(X_train,Y_train)\n",
    "print('Test score:', linear_svm.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) decision trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X_train,Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = DecisionTreeClassifier(max_depth = 4, random_state=0)\n",
    "tree1.fit(X_train,Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree1.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree1.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (7) decision tree regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "treeRegr = DecisionTreeRegressor(max_depth=3).fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(treeRegr.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(treeRegr.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=2, random_state=5)\n",
    "forest.fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest1 = RandomForestClassifier(n_estimators=10, random_state=5)\n",
    "forest1.fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest1.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest1.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (9) Gradient Boosted Regression Trees\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbrt = GradientBoostingClassifier(random_state=0)\n",
    "gbrt.fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, Y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt1 = GradientBoostingClassifier(random_state=0,max_depth = 1)\n",
    "gbrt1.fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt1.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt1.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt001 = GradientBoostingClassifier(random_state=0,learning_rate = 0.01)\n",
    "gbrt001.fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt001.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt001.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(10) Neural Networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(solver='lbfgs', random_state=0).fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hidden layer\n",
    "mlp1 = MLPClassifier(solver='lbfgs', random_state=0,hidden_layer_sizes=[10]).fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp1.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp1.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two hidden layers\n",
    "mlp2 = MLPClassifier(solver='lbfgs', random_state=0,hidden_layer_sizes=[10,10]).fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp2.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp2.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two hidden layers with tanh nonlinearity\n",
    "mlp2tanh = MLPClassifier(solver='lbfgs', activation='tanh', random_state=0,hidden_layer_sizes=[10,10]).fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp2tanh.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp2tanh.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum iteration is 1000\n",
    "mlp1000 = MLPClassifier(max_iter=1000, alpha=1, random_state=0)\n",
    "mlp1000.fit(X_train,Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(mlp1000.score(X_train, Y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(mlp1000.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (11) Uncertainty in multiclass classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
